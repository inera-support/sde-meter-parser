"""
Dashboard Streamlit pour la conversion des relev√©s manuels de compteurs
"""

import streamlit as st
import pandas as pd
import zipfile
import io
from datetime import datetime
from typing import List, Dict, Any
import tempfile
import os

# Import des modules locaux
from parsers import FileProcessor, FileProcessingResult
from validation import QualityReportGenerator
from export import EnergyWorxExporter, SummaryTableGenerator
from visualization import create_load_curve_chart, create_index_chart, get_readings_by_cldn_and_type

# Configuration de la page
st.set_page_config(
    page_title="Parser Relev√©s Manuels Compteurs",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 0.375rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 0.375rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.375rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 0.375rem;
        padding: 1rem;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """Fonction principale de l'application"""
    
    # En-t√™te
    st.markdown('<h1 class="main-header">‚ö° Parser Relev√©s Manuels Compteurs</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    Cette application permet de convertir les relev√©s manuels de compteurs √©lectriques 
    (CSV BlueLink, XML MAP110, Excel) vers le format EnergyWorx pour l'ingestion dans le MDMS.
    """)
    
    # Initialisation des variables de session
    if 'processing_results' not in st.session_state:
        st.session_state.processing_results = []
    if 'quality_report' not in st.session_state:
        st.session_state.quality_report = None
    if 'exported_files' not in st.session_state:
        st.session_state.exported_files = {}
    
    # Sidebar
    with st.sidebar:
        st.header("üìã Instructions")
        st.markdown("""
        1. **Uploadez vos fichiers** : CSV, XML, Excel ou ZIP
        2. **V√©rifiez les r√©sultats** dans le tableau de synth√®se
        3. **T√©l√©chargez les fichiers** convertis au format EnergyWorx
        
        **Formats support√©s :**
        - CSV BlueLink (compteurs Ensor)
        - XML MAP110 (compteurs Landis)
        - Excel BlueLink
        - Fichiers ZIP contenant les formats ci-dessus
        """)
        
        st.header("üîß Param√®tres")
        
        # Option pour forcer un CLDN
        force_cldn = st.text_input(
            "CLDN forc√© (optionnel)",
            help="Si les fichiers ne contiennent pas de CLDN, utilisez cette valeur"
        )
        
        # Option pour le fuseau horaire
        timezone_option = st.selectbox(
            "Fuseau horaire source",
            ["Europe/Zurich", "Europe/Paris", "UTC"],
            help="Fuseau horaire des donn√©es d'entr√©e"
        )
        
        st.header("üìä Aide - Colonnes de compl√©tude")
        st.markdown("""
        **Colonnes "Complet" et "Pourcentage" :**
        
        Ces colonnes indiquent la **qualit√© temporelle** des donn√©es :
        
        - **Complet** : True/False selon si ‚â•95% de couverture
        - **Pourcentage** : Pourcentage exact de couverture (0-100%)
        
        **Calcul :**
        1. P√©riode totale = Derni√®re lecture - Premi√®re lecture
        2. Lectures attendues = P√©riode √∑ 15 minutes + 1
        3. Pourcentage = (Lectures r√©elles √∑ Lectures attendues) √ó 100
        
        **Exemple :**
        - 24h de donn√©es ‚Üí 97 lectures attendues
        - 92 lectures r√©elles ‚Üí 94.8% ‚Üí Complet = False
        """)
    
    # Section principale
    tab1, tab2, tab3, tab4 = st.tabs(["üìÅ Upload", "üìä Synth√®se", "üîç Qualit√©", "üíæ Export"])
    
    with tab1:
        upload_section(force_cldn, timezone_option)
    
    with tab2:
        summary_section()
    
    with tab3:
        quality_section()
    
    with tab4:
        export_section()

def upload_section(force_cldn: str, timezone_option: str):
    """Section d'upload des fichiers"""
    
    st.header("üìÅ Upload des fichiers")
    
    # Zone de drag & drop
    uploaded_files = st.file_uploader(
        "Glissez-d√©posez vos fichiers ou cliquez pour s√©lectionner",
        type=['csv', 'xml', 'xlsx', 'xls', 'zip'],
        accept_multiple_files=True,
        help="Formats support√©s : CSV BlueLink, XML MAP110, Excel BlueLink, ZIP"
    )
    
    if uploaded_files:
        st.success(f"‚úÖ {len(uploaded_files)} fichier(s) s√©lectionn√©(s)")
        
        # Bouton de traitement
        if st.button("üîÑ Traiter les fichiers", type="primary"):
            process_files(uploaded_files, force_cldn, timezone_option)
    

def process_files(uploaded_files: List, force_cldn: str, timezone_option: str):
    """Traite les fichiers upload√©s"""
    
    with st.spinner("üîÑ Traitement des fichiers en cours..."):
        processor = FileProcessor()
        processing_results = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, uploaded_file in enumerate(uploaded_files):
            status_text.text(f"Traitement de {uploaded_file.name}...")
            
            try:
                # Lecture du contenu du fichier
                file_content = uploaded_file.read()
                
                # Traitement selon le type de fichier
                if uploaded_file.name.lower().endswith('.zip'):
                    results = processor.process_zip(file_content, uploaded_file.name)
                    processing_results.extend(results)
                else:
                    result = processor.process_file(file_content, uploaded_file.name)
                    processing_results.append(result)
                
                # Application du CLDN forc√© si n√©cessaire
                if force_cldn:
                    for result in processing_results:
                        if result.success and result.readings:
                            for reading in result.readings:
                                if not reading.cldn:
                                    reading.cldn = force_cldn
                
            except Exception as e:
                error_result = FileProcessingResult(
                    uploaded_file.name, 
                    False, 
                    errors=[f"Erreur lors du traitement: {str(e)}"]
                )
                processing_results.append(error_result)
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        # G√©n√©ration du rapport de qualit√©
        quality_generator = QualityReportGenerator()
        quality_report = quality_generator.generate_report(processing_results)
        
        # Mise √† jour de la session avec les fichiers originaux pour conserver les tailles
        st.session_state.processing_results = processing_results
        st.session_state.quality_report = quality_report
        st.session_state.uploaded_files_info = {f.name: f.size for f in uploaded_files}
        
        status_text.text("‚úÖ Traitement termin√©!")
        progress_bar.empty()
        
        # Affichage des r√©sultats
        display_processing_results(processing_results)

def display_processing_results(processing_results: List[FileProcessingResult]):
    """Affiche les r√©sultats du traitement"""
    
    st.subheader("üìä R√©sultats du traitement")
    
    # Statistiques globales
    total_files = len(processing_results)
    successful_files = sum(1 for r in processing_results if r.success)
    failed_files = total_files - successful_files
    total_readings = sum(len(r.readings) for r in processing_results)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Fichiers trait√©s", total_files)
    
    with col2:
        st.metric("Succ√®s", successful_files, delta=f"{successful_files/total_files*100:.1f}%" if total_files > 0 else "0%")
    
    with col3:
        st.metric("√âchecs", failed_files)
    
    with col4:
        st.metric("Lectures totales", total_readings)
    
    # Mise √† jour du tableau des fichiers avec les r√©sultats
    if processing_results:
        st.subheader("üìã √âtat des fichiers")
        
        # Explication des colonnes
        with st.expander("‚ÑπÔ∏è Explication des colonnes"):
            st.markdown("""
            **Colonnes du tableau :**
            
            - **Nom** : Nom du fichier trait√©
            - **Taille** : Taille r√©elle du fichier en KB
            - **Type** : Extension du fichier (CSV, XML, XLSX, ZIP)
            - **Statut** : 
              - ‚úÖ **Succ√®s** : Fichier trait√© sans erreur critique
              - ‚ùå **√âchec** : Erreur lors du traitement du fichier
            - **Nombre de canaux** : Nombre de types de mesures diff√©rents dans le fichier
            - **Mesures temporelles** : Nombre de mesures d'√©nergie extraites du fichier
            - **Erreurs** : Nombre d'erreurs critiques d√©tect√©es (emp√™chent le traitement)
            - **Avertissements** : Nombre d'avertissements d√©tect√©s (n'emp√™chent pas le traitement)
            
            **Types d'erreurs courantes :**
            - Format de fichier non support√©
            - Structure XML/CSV invalide
            - Donn√©es manquantes critiques (CLDN, timestamps)
            - Encodage de fichier non reconnu
            
            **Types d'avertissements courants :**
            - Valeurs manquantes dans certaines colonnes
            - Timestamps en dehors de la plage attendue
            - Valeurs d'√©nergie anormalement √©lev√©es ou n√©gatives
            - Doublons d√©tect√©s dans les donn√©es
            """)
        
        # Cr√©er un dictionnaire pour mapper les r√©sultats par nom de fichier
        results_by_filename = {result.filename: result for result in processing_results}
        
        # Mettre √† jour les informations des fichiers
        updated_file_info = []
        for result in processing_results:
            status = "‚úÖ Succ√®s" if result.success else "‚ùå √âchec"
            
            # R√©cup√©rer la taille r√©elle du fichier si disponible
            file_size = st.session_state.get('uploaded_files_info', {}).get(result.filename, 0)
            if file_size > 0:
                size_str = f"{file_size / 1024:.1f} KB"
            else:
                size_str = f"{len(result.readings) * 0.1:.1f} KB"  # Estimation bas√©e sur les lectures
            
            # Compter les types uniques pour ce fichier
            unique_types = set(r.reading_type for r in result.readings)
            
            updated_file_info.append({
                'Nom': result.filename,
                'Taille': size_str,
                'Type': result.filename.split('.')[-1].upper(),
                'Statut': status,
                'Nombre de canaux': len(unique_types),
                'Mesures temporelles': len(result.readings),
                'Erreurs': len(result.errors),
                'Avertissements': len(result.warnings)
            })
        
        df_updated = pd.DataFrame(updated_file_info)
        st.dataframe(df_updated, use_container_width=True)
        
        # Affichage des erreurs
        errors_found = any(len(r.errors) > 0 for r in processing_results)
        if errors_found:
            st.subheader("‚ùå Erreurs d√©tect√©es")
            
            for result in processing_results:
                if result.errors:
                    with st.expander(f"Erreurs dans {result.filename}"):
                        for error in result.errors:
                            st.error(error)

def summary_section():
    """Section du tableau de synth√®se"""
    
    st.header("üìä Tableau de synth√®se des compteurs relev√©s")
    
    if not st.session_state.processing_results:
        st.info("Aucun fichier trait√©. Veuillez d'abord uploader et traiter des fichiers.")
        return
    
    # G√©n√©ration du tableau de synth√®se
    summary_generator = SummaryTableGenerator()
    summary_data = summary_generator.generate_summary_table(st.session_state.processing_results)
    
    if not summary_data:
        st.warning("Aucune donn√©e valide trouv√©e pour g√©n√©rer le tableau de synth√®se.")
        return
    
    # Affichage du tableau
    df_summary = pd.DataFrame(summary_data)
    
    # Filtres
    col1, col2, col3 = st.columns(3)
    
    with col1:
        cldn_filter = st.multiselect(
            "Filtrer par CLDN",
            options=df_summary['CLDN'].unique(),
            default=df_summary['CLDN'].unique()
        )
    
    with col2:
        status_filter = st.multiselect(
            "Filtrer par statut de validation",
            options=df_summary['Statut Validation'].unique(),
            default=df_summary['Statut Validation'].unique()
        )
    
    with col3:
        energy_type_filter = st.multiselect(
            "Filtrer par type d'√©nergie",
            options=df_summary['Type √ânergie'].unique(),
            default=df_summary['Type √ânergie'].unique()
        )
    
    # Application des filtres
    filtered_df = df_summary[
        (df_summary['CLDN'].isin(cldn_filter)) &
        (df_summary['Statut Validation'].isin(status_filter)) &
        (df_summary['Type √ânergie'].isin(energy_type_filter))
    ]
    
    # Explication des colonnes
    with st.expander("‚ÑπÔ∏è Explication des colonnes"):
        st.markdown("""
        **Colonnes principales :**
        - **CLDN** : Identifiant unique du compteur
        - **Libell√© Original** : Nom du registre tel qu'il appara√Æt dans les donn√©es sources
        - **Code OBIS** : Code standard selon la norme IEC 62056-61
        - **Description Standard** : Signification du code OBIS selon la norme
        - **Type √ânergie** : Active, R√©active, Apparente, Puissance
        - **Direction/Quadrant** : Direction (Import√©e/Export√©e) ou Quadrant (Q1/Q2/Q3/Q4)
        - **Unit√©** : Unit√© de mesure (kWh, kvarh, kVAh, kW)
        - **Statut Validation** : CORRECT, AVERTISSEMENT, ERREUR, INCONNU
        - **Type de fichier** : Format source des donn√©es (CSV BlueLink, XML MAP110 E450, etc.)
        
        **Colonnes de comptage :**
        - **Nombre de canaux** : Nombre de types de mesures diff√©rents pour ce compteur (ex: 9 pour E450)
        - **Mesures temporelles** : Nombre de mesures pour ce type sp√©cifique (ex: 4587 pour A+ Load1)
        
        **Colonnes de compl√©tude :**
        - **Complet** : Indique si les donn√©es couvrent exactement 100% de la p√©riode attendue
        - **Pourcentage** : Pourcentage de couverture des donn√©es (0-100%)
        
        **Calcul de la compl√©tude :**
        1. **P√©riode totale** : De la premi√®re √† la derni√®re lecture
        2. **Lectures attendues** : Dur√©e totale √∑ 15 minutes + 1
        3. **Pourcentage** : (Lectures r√©elles √∑ Lectures attendues) √ó 100
        4. **Complet** : True si = 100%, False sinon
        
        **Exemple pour compteur E450 :**
        - **Nombre de canaux** : 9 (A+ import, A- export, Q1, Q2, Q3, Q4, Load1, Load2, Quality)
        - **Mesures temporelles** : 4587 (pour le canal A+ Load1 sur 15 minutes)
        """)
    
    # Affichage du tableau filtr√©
    st.dataframe(filtered_df, use_container_width=True)
    
    # Avertissements pour les erreurs OBIS
    error_rows = filtered_df[filtered_df['Statut Validation'] == 'ERREUR']
    if not error_rows.empty:
        st.subheader("‚ö†Ô∏è Erreurs OBIS d√©tect√©es")
        st.warning(f"**{len(error_rows)} registre(s) avec des erreurs d'attribution OBIS d√©tect√©es !**")
        
        # Filtres sp√©cifiques pour les erreurs
        col1, col2 = st.columns(2)
        
        with col1:
            error_type_filter = st.multiselect(
                "Filtrer par type d'erreur",
                options=error_rows['Type √ânergie'].unique(),
                default=error_rows['Type √ânergie'].unique(),
                key="error_type_filter"
            )
        
        with col2:
            error_code_filter = st.multiselect(
                "Filtrer par code OBIS probl√©matique",
                options=error_rows['Code OBIS'].unique(),
                default=error_rows['Code OBIS'].unique(),
                key="error_code_filter"
            )
        
        # Application des filtres d'erreur
        filtered_errors = error_rows[
            (error_rows['Type √ânergie'].isin(error_type_filter)) &
            (error_rows['Code OBIS'].isin(error_code_filter))
        ]
        
        for _, row in filtered_errors.iterrows():
            with st.expander(f"‚ùå {row['CLDN']} - {row['Libell√© Original']}"):
                st.error(f"**Code OBIS:** {row['Code OBIS']}")
                st.write(f"**Description standard:** {row['Description Standard']}")
                st.write(f"**Probl√®me:** {row['Commentaire']}")
                st.write(f"**Recommandation:** V√©rifiez la configuration du compteur ou contactez le fournisseur des donn√©es.")
        
        # R√©sum√© des erreurs par type
        st.subheader("üìä R√©sum√© des erreurs par type")
        
        error_summary = error_rows.groupby(['Type √ânergie', 'Code OBIS']).size().reset_index(name='Nombre')
        error_summary = error_summary.sort_values('Nombre', ascending=False)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Par type d'√©nergie:**")
            type_summary = error_rows.groupby('Type √ânergie').size().reset_index(name='Nombre')
            for _, row in type_summary.iterrows():
                st.write(f"- {row['Type √ânergie']}: {row['Nombre']} erreur(s)")
        
        with col2:
            st.write("**Par code OBIS:**")
            code_summary = error_rows.groupby('Code OBIS').size().reset_index(name='Nombre')
            for _, row in code_summary.iterrows():
                st.write(f"- {row['Code OBIS']}: {row['Nombre']} erreur(s)")
    
    # Statistiques du tableau
    st.subheader("üìà Statistiques")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Compteurs uniques", len(filtered_df['CLDN'].unique()))
    
    with col2:
        st.metric("Types d'√©nergie uniques", len(filtered_df['Type √ânergie'].unique()))
    
    with col3:
        complete_count = len(filtered_df[filtered_df['Complet'] == True])
        incomplete_count = len(filtered_df[filtered_df['Complet'] == False])
        st.metric("Registres complets", complete_count, delta=f"{complete_count/len(filtered_df)*100:.1f}%" if len(filtered_df) > 0 else "0%")
        
        # Explication de la compl√©tude
        if incomplete_count > 0:
            st.caption(f"‚ö†Ô∏è {incomplete_count} registre(s) incomplet(s) d√©tect√©(s)")
            st.caption("Un registre est consid√©r√© comme complet s'il couvre exactement 100% de la p√©riode attendue")
    
    with col4:
        # Calculer le nombre total de canaux uniques
        total_channels = filtered_df['Nombre de canaux'].sum() if len(filtered_df) > 0 else 0
        total_measurements = filtered_df['Mesures temporelles'].sum() if len(filtered_df) > 0 else 0
        st.metric("Canaux total", total_channels)
        st.caption(f"Mesures temporelles: {total_measurements:,}")
    
    # Section de visualisation des courbes de charge
    st.divider()
    st.subheader("üìà Visualisation des courbes de charge")
    
    if len(filtered_df) > 0:
        # S√©lection du CLDN et du type de lecture
        col1, col2 = st.columns(2)
        
        with col1:
            selected_cldn = st.selectbox(
                "S√©lectionner un compteur (CLDN)",
                options=sorted(filtered_df['CLDN'].unique()),
                key="chart_cldn_select"
            )
        
        with col2:
            # Filtrer les types de lecture disponibles pour le CLDN s√©lectionn√©
            available_types = filtered_df[
                filtered_df['CLDN'] == selected_cldn
            ]['Libell√© Original'].unique()
            
            selected_reading_type = st.selectbox(
                "S√©lectionner un type de lecture",
                options=sorted(available_types),
                key="chart_reading_type_select"
            )
        
        # R√©cup√©rer les informations du type s√©lectionn√©
        selected_row = filtered_df[
            (filtered_df['CLDN'] == selected_cldn) &
            (filtered_df['Libell√© Original'] == selected_reading_type)
        ].iloc[0]
        
        # R√©cup√©rer les lectures correspondantes
        # Utiliser le mapping OBIS du g√©n√©rateur de synth√®se pour trouver le reading_type
        summary_generator = SummaryTableGenerator()
        readings = get_readings_by_cldn_and_type(
            st.session_state.processing_results,
            selected_cldn,
            selected_reading_type,
            obis_mapping=summary_generator.obis_mapping
        )
        
        if readings:
            # Afficher les informations
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("P√©riode", f"{selected_row['Date min'][:10]} ‚Üí {selected_row['Date max'][:10]}")
            with col2:
                st.metric("Mesures", f"{len(readings):,}")
            with col3:
                st.metric("Compl√©tude", selected_row['Pourcentage'])
            with col4:
                st.metric("Unit√©", selected_row['Unit√©'])
            
            # Options d'affichage
            col1, col2 = st.columns(2)
            with col1:
                show_load_curve = st.checkbox("Afficher la courbe de charge", value=True, key="show_load_curve")
            with col2:
                show_index = st.checkbox("Afficher l'√©volution de l'index", value=False, key="show_index")
            
            # Graphique de courbe de charge
            if show_load_curve:
                st.markdown("#### Courbe de charge avec d√©tection des trous")
                st.caption("üîµ Bleu = Donn√©es r√©elles | üü† Orange = Trous < 1 jour | üî¥ Rouge = Trous > 1 jour")
                
                chart, availability_chart = create_load_curve_chart(
                    readings=readings,
                    title="Courbe de charge",
                    cldn=selected_cldn,
                    reading_type=selected_reading_type,
                    interval_minutes=15
                )
                
                # Afficher le graphique de disponibilit√© d'abord
                st.plotly_chart(availability_chart, use_container_width=True)
                
                # Puis la courbe de charge d√©taill√©e
                st.plotly_chart(chart, use_container_width=True)
            
            # Graphique d'√©volution de l'index
            if show_index:
                st.markdown("#### √âvolution de l'index (cumulatif)")
                
                index_chart = create_index_chart(
                    readings=readings,
                    title="√âvolution de l'index",
                    cldn=selected_cldn,
                    reading_type=selected_reading_type
                )
                st.plotly_chart(index_chart, use_container_width=True)
        else:
            st.warning(f"Aucune lecture trouv√©e pour {selected_cldn} - {selected_reading_type}")
    else:
        st.info("S√©lectionnez des donn√©es dans le tableau ci-dessus pour afficher les graphiques.")
    
    # Boutons d'export
    st.divider()
    st.subheader("üíæ Export du tableau")
    
    col1, col2 = st.columns(2)
    
    with col1:
        csv_data = summary_generator.export_summary_to_csv(filtered_df.to_dict('records'))
        st.download_button(
            label="üìÑ T√©l√©charger CSV",
            data=csv_data,
            file_name=f"synth√®se_compteurs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    
    with col2:
        excel_data = summary_generator.export_summary_to_excel(filtered_df.to_dict('records'))
        st.download_button(
            label="üìä T√©l√©charger Excel",
            data=excel_data,
            file_name=f"synth√®se_compteurs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

def quality_section():
    """Section de contr√¥le qualit√©"""
    
    st.header("üîç Contr√¥le qualit√© des donn√©es")
    
    if not st.session_state.quality_report:
        st.info("Aucun rapport de qualit√© disponible. Veuillez d'abord traiter des fichiers.")
        return
    
    report = st.session_state.quality_report
    
    # R√©sum√© global
    st.subheader("üìä R√©sum√© global")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Fichiers trait√©s", report['summary']['total_files'])
    
    with col2:
        st.metric("Lectures totales", report['summary']['total_readings'])
    
    with col3:
        st.metric("Erreurs", report['summary']['total_errors'])
    
    with col4:
        st.metric("Avertissements", report['summary']['total_warnings'])
    
    # Recommandations
    if report['recommendations']:
        st.subheader("üí° Recommandations")
        
        for recommendation in report['recommendations']:
            st.warning(recommendation)
    
    # D√©tail par fichier
    st.subheader("üìã D√©tail par fichier")
    
    for file_report in report['files']:
        with st.expander(f"{file_report['filename']} - {'‚úÖ' if file_report['success'] else '‚ùå'}"):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Lectures:** {file_report['readings_count']}")
                st.write(f"**Erreurs:** {len(file_report['errors'])}")
                st.write(f"**Avertissements:** {len(file_report['warnings'])}")
            
            with col2:
                if file_report['validation']:
                    validation = file_report['validation']
                    st.write(f"**Score de qualit√©:** {validation['quality_score']:.1f}%")
                    
                    if validation['statistics']:
                        stats = validation['statistics']
                        st.write(f"**Plage de dates:** {stats['date_range']['start'].strftime('%Y-%m-%d')} √† {stats['date_range']['end'].strftime('%Y-%m-%d')}")
            
            # Erreurs
            if file_report['errors']:
                st.write("**Erreurs:**")
                for error in file_report['errors']:
                    st.error(error)
            
            # Avertissements
            if file_report['warnings']:
                st.write("**Avertissements:**")
                for warning in file_report['warnings']:
                    st.warning(warning)

def export_section():
    """Section d'export des fichiers"""
    
    st.header("üíæ Export des fichiers EnergyWorx")
    
    if not st.session_state.processing_results:
        st.info("Aucun fichier trait√©. Veuillez d'abord uploader et traiter des fichiers.")
        return
    
    # G√©n√©ration des fichiers d'export
    if st.button("üîÑ G√©n√©rer les fichiers EnergyWorx", type="primary"):
        with st.spinner("G√©n√©ration des fichiers en cours..."):
            exporter = EnergyWorxExporter()
            exported_files = exporter.export_to_files(st.session_state.processing_results)
            st.session_state.exported_files = exported_files
        
        st.success(f"‚úÖ {len(exported_files)} fichier(s) g√©n√©r√©(s)")
    
    # Affichage des fichiers g√©n√©r√©s
    if st.session_state.exported_files:
        st.subheader("üìÅ Fichiers g√©n√©r√©s")
        
        file_list = []
        for filename, content in st.session_state.exported_files.items():
            file_list.append({
                'Nom': filename,
                'Taille': f"{len(content) / 1024:.1f} KB"
            })
        
        df_files = pd.DataFrame(file_list)
        st.dataframe(df_files, use_container_width=True)
        
        # Boutons de t√©l√©chargement
        st.subheader("üì• T√©l√©chargement")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # T√©l√©chargement individuel
            st.write("**T√©l√©chargement individuel:**")
            
            for filename, content in st.session_state.exported_files.items():
                st.download_button(
                    label=f"üìÑ {filename}",
                    data=content,
                    file_name=filename,
                    mime="application/json"
                )
        
        with col2:
            # T√©l√©chargement en lot (ZIP)
            st.write("**T√©l√©chargement en lot:**")
            
            exporter = EnergyWorxExporter()
            zip_content = exporter.create_zip_export(st.session_state.exported_files)
            
            st.download_button(
                label="üì¶ T√©l√©charger tous les fichiers (ZIP)",
                data=zip_content,
                file_name=f"meter_readings_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                mime="application/zip"
            )
    
    # Instructions d'ingestion
    st.subheader("üìã Instructions d'ingestion")
    
    st.markdown("""
    **Pour ing√©rer les fichiers dans EnergyWorx :**
    
    1. T√©l√©chargez les fichiers JSON g√©n√©r√©s
    2. Utilisez l'API EnergyWorx ou l'interface d'ingestion
    3. V√©rifiez que les CLDN correspondent aux compteurs dans le syst√®me
    4. Les fichiers sont au format standard EnergyWorx MeterReadings
    
    **Format des fichiers :**
    - Chaque fichier contient les lectures d'un compteur (CLDN)
    - Les timestamps sont en UTC
    - Les valeurs sont en kWh/kvarh selon le type de registre
    - Les ReadingTypes correspondent aux standards EnergyWorx
    """)

if __name__ == "__main__":
    main()
